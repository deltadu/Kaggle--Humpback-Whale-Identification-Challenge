{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jdu12\\Anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "train_images = glob(\"C:/Users/jdu12/Desktop/humpback/train/*jpg\")\n",
    "test_images = glob(\"C:/Users/jdu12/Desktop/humpback/test/*jpg\")\n",
    "df = pd.read_csv(\"C:/Users/jdu12/Desktop/humpback/train.csv\")\n",
    "\n",
    "#df[\"Image\"] = df[\"Image\"].map( lambda x : \"C:/Users/jdu12/Desktop/humpback/input/train/\"+x)\n",
    "#ImageToLabelDict = dict( zip( df[\"Image\"], df[\"Id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
    "# load a single image to np array\n",
    "def get_image(img_path):\n",
    "    img = load_img(img_path, target_size=(224, 224))#.convert('L')\n",
    "    img = img_to_array(img)\n",
    "    #img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9850\n",
      "(9850, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# loading train images\n",
    "trainPaths = list(paths.list_images('C:/Users/jdu12/Desktop/humpback/train/'))\n",
    "print(len(trainPaths))\n",
    "train = np.array([get_image(img_path) for img_path in trainPaths])\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 29,
=======
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = load_img(trainPaths[0], target_size=(299, 299))\n",
    "#a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels):\n",
    "    one_hot = []\n",
    "    seen_id = set()\n",
    "    id2class = dict()\n",
    "    counter = 0\n",
    "    for id in labels:\n",
    "        if id not in seen_id:\n",
    "            seen_id.add(id)\n",
    "            one_hot.append(counter)\n",
    "            id2class[id] = counter\n",
    "            counter += 1\n",
    "        else:\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "            one_hot_labels.append(id2class[id])\n",
    "    one_hot_labels = to_categorical(one_hot_labels, num_classes = 4251)\n",
    "    return one_hot_labels, class2id, id2class"
=======
    "            one_hot.append(id2class[id])\n",
    "    one_hot = to_categorical(one_hot, num_classes = 4251)\n",
    "    return one_hot"
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
    "            one_hot.append(id2class[id])\n",
    "    one_hot = to_categorical(one_hot, num_classes = 4251)\n",
    "    return one_hot"
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
    "            one_hot.append(id2class[id])\n",
    "    one_hot = to_categorical(one_hot, num_classes = 4251)\n",
    "    return one_hot"
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 7,
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
   "execution_count": 7,
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
   "execution_count": 7,
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/jdu12/Desktop/humpback/train.csv\")\n",
    "\n",
    "labels = df['Id']\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "labels, class2id, id2class = to_one_hot(labels)\n",
=======
    "labels = to_one_hot(labels)\n",
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
    "labels = to_one_hot(labels)\n",
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
    "labels = to_one_hot(labels)\n",
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
    "#print(labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and val\n",
    "# The dataset is super unbalanced, as there are many classes that contains only 1 image\n",
    "# As a result, train/val data cannot be split before generating more data by augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data generator\n",
    "#use of an image generator for preprocessing and data augmentation\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
    "x_train = train_images.astype(\"float32\")\n",
    "y_train = labels\n",
    "\n",
    "# define data generator\n",
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
    "image_gen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the model\n",
    "model = keras.applications.densenet.DenseNet121(include_top=True, weights=None, classes=4251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "Epoch 1/180\n",
      "307/307 [==============================] - 142s 462ms/step - loss: 8.4272 - acc: 0.0603\n",
      "Epoch 2/180\n",
      "307/307 [==============================] - 126s 411ms/step - loss: 7.8322 - acc: 0.0717\n",
      "Epoch 3/180\n",
      "307/307 [==============================] - 125s 408ms/step - loss: 7.3146 - acc: 0.0747\n",
      "Epoch 4/180\n",
      "307/307 [==============================] - 125s 407ms/step - loss: 6.9169 - acc: 0.0732\n",
      "Epoch 5/180\n",
      "307/307 [==============================] - 122s 397ms/step - loss: 6.5652 - acc: 0.0694\n",
      "Epoch 6/180\n",
      "307/307 [==============================] - 118s 385ms/step - loss: 6.2235 - acc: 0.0670\n",
      "Epoch 7/180\n",
      "307/307 [==============================] - 120s 389ms/step - loss: 5.9016 - acc: 0.0657\n",
      "Epoch 8/180\n",
      "307/307 [==============================] - 122s 398ms/step - loss: 5.5103 - acc: 0.0715\n",
      "Epoch 9/180\n",
      "307/307 [==============================] - 122s 397ms/step - loss: 5.1645 - acc: 0.0824\n",
      "Epoch 10/180\n",
      "307/307 [==============================] - 124s 403ms/step - loss: 4.7750 - acc: 0.0989\n",
      "Epoch 11/180\n",
      "307/307 [==============================] - 124s 403ms/step - loss: 4.3870 - acc: 0.1315\n",
      "Epoch 12/180\n",
      "307/307 [==============================] - 122s 398ms/step - loss: 3.9874 - acc: 0.1735\n",
      "Epoch 13/180\n",
      "307/307 [==============================] - 122s 398ms/step - loss: 3.6360 - acc: 0.2197\n",
      "Epoch 14/180\n",
      "307/307 [==============================] - 123s 400ms/step - loss: 3.2460 - acc: 0.2727\n",
      "Epoch 15/180\n",
      "307/307 [==============================] - 120s 390ms/step - loss: 2.8787 - acc: 0.3397\n",
      "Epoch 16/180\n",
      "307/307 [==============================] - 124s 405ms/step - loss: 2.5584 - acc: 0.3976\n",
      "Epoch 17/180\n",
      "307/307 [==============================] - 125s 408ms/step - loss: 2.2692 - acc: 0.4560\n",
      "Epoch 18/180\n",
      "307/307 [==============================] - 124s 403ms/step - loss: 1.9970 - acc: 0.5111\n",
      "Epoch 19/180\n",
      "307/307 [==============================] - 124s 404ms/step - loss: 1.8002 - acc: 0.5436\n",
      "Epoch 20/180\n",
      "307/307 [==============================] - 125s 407ms/step - loss: 1.5999 - acc: 0.5906\n",
      "Epoch 21/180\n",
      "307/307 [==============================] - 119s 389ms/step - loss: 1.4457 - acc: 0.6232\n",
      "Epoch 22/180\n",
      "307/307 [==============================] - 122s 396ms/step - loss: 1.2858 - acc: 0.6617\n",
      "Epoch 23/180\n",
      "307/307 [==============================] - 123s 401ms/step - loss: 1.1924 - acc: 0.6817\n",
      "Epoch 24/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 1.0663 - acc: 0.7113\n",
      "Epoch 25/180\n",
      "307/307 [==============================] - 119s 387ms/step - loss: 0.9432 - acc: 0.7411\n",
      "Epoch 26/180\n",
      "307/307 [==============================] - 119s 388ms/step - loss: 0.9034 - acc: 0.7500\n",
      "Epoch 27/180\n",
      "307/307 [==============================] - 118s 386ms/step - loss: 0.8298 - acc: 0.7723\n",
      "Epoch 28/180\n",
      "307/307 [==============================] - 118s 385ms/step - loss: 0.7630 - acc: 0.7833\n",
      "Epoch 29/180\n",
      "307/307 [==============================] - 119s 389ms/step - loss: 0.7026 - acc: 0.8047\n",
      "Epoch 30/180\n",
      "307/307 [==============================] - 121s 393ms/step - loss: 0.6725 - acc: 0.8100\n",
      "Epoch 31/180\n",
      "307/307 [==============================] - 122s 396ms/step - loss: 0.6025 - acc: 0.8278\n",
      "Epoch 32/180\n",
      "307/307 [==============================] - 122s 396ms/step - loss: 0.5765 - acc: 0.8337\n",
      "Epoch 33/180\n",
      "307/307 [==============================] - 122s 396ms/step - loss: 0.5339 - acc: 0.8470\n",
      "Epoch 34/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 0.5261 - acc: 0.8492\n",
      "Epoch 35/180\n",
      "307/307 [==============================] - 122s 396ms/step - loss: 0.5077 - acc: 0.8576\n",
      "Epoch 36/180\n",
      "307/307 [==============================] - 121s 394ms/step - loss: 0.4878 - acc: 0.8623\n",
      "Epoch 37/180\n",
      "307/307 [==============================] - 121s 394ms/step - loss: 0.4424 - acc: 0.8726\n",
      "Epoch 38/180\n",
      "307/307 [==============================] - 107s 349ms/step - loss: 0.4656 - acc: 0.8665\n",
      "Epoch 39/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.4263 - acc: 0.8796\n",
      "Epoch 40/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.4013 - acc: 0.8842\n",
      "Epoch 41/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.3973 - acc: 0.8902\n",
      "Epoch 42/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.3887 - acc: 0.8891\n",
      "Epoch 43/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.3659 - acc: 0.8964\n",
      "Epoch 44/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.3611 - acc: 0.8985\n",
      "Epoch 45/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.3401 - acc: 0.9031\n",
      "Epoch 46/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.3373 - acc: 0.9077\n",
      "Epoch 47/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.3070 - acc: 0.9116\n",
      "Epoch 48/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.3272 - acc: 0.9089\n",
      "Epoch 49/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.3165 - acc: 0.9124\n",
      "Epoch 50/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2964 - acc: 0.9194\n",
      "Epoch 51/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.3078 - acc: 0.9168\n",
      "Epoch 52/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2927 - acc: 0.9174\n",
      "Epoch 53/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2692 - acc: 0.9279\n",
      "Epoch 54/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2781 - acc: 0.9224\n",
      "Epoch 55/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2846 - acc: 0.9209\n",
      "Epoch 56/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2560 - acc: 0.9298\n",
      "Epoch 57/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2619 - acc: 0.9270\n",
      "Epoch 58/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2467 - acc: 0.9318\n",
      "Epoch 59/180\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.2566 - acc: 0.9298\n",
      "Epoch 60/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2559 - acc: 0.9313\n",
      "Epoch 61/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2491 - acc: 0.9282\n",
      "Epoch 62/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2406 - acc: 0.9354\n",
      "Epoch 63/180\n",
      "307/307 [==============================] - 110s 360ms/step - loss: 0.2481 - acc: 0.9315\n",
      "Epoch 64/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2259 - acc: 0.9389\n",
      "Epoch 65/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2172 - acc: 0.9446\n",
      "Epoch 66/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2358 - acc: 0.9386\n",
      "Epoch 67/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2184 - acc: 0.9401\n",
      "Epoch 68/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2000 - acc: 0.9469\n",
      "Epoch 69/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2138 - acc: 0.9434\n",
      "Epoch 70/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2032 - acc: 0.9459\n",
      "Epoch 71/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2150 - acc: 0.9419\n",
      "Epoch 72/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2041 - acc: 0.9482\n",
      "Epoch 73/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2065 - acc: 0.9454\n",
      "Epoch 74/180\n",
      "307/307 [==============================] - 111s 363ms/step - loss: 0.2078 - acc: 0.9454\n",
      "Epoch 75/180\n",
      "307/307 [==============================] - 119s 387ms/step - loss: 0.1906 - acc: 0.9481\n",
      "Epoch 76/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 0.2010 - acc: 0.9474\n",
      "Epoch 77/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 0.1925 - acc: 0.9487\n",
      "Epoch 78/180\n",
      "307/307 [==============================] - 121s 393ms/step - loss: 0.1788 - acc: 0.9519\n",
      "Epoch 79/180\n",
      "307/307 [==============================] - 120s 390ms/step - loss: 0.1925 - acc: 0.9491\n",
      "Epoch 80/180\n",
      "307/307 [==============================] - 121s 393ms/step - loss: 0.1939 - acc: 0.9496\n",
      "Epoch 81/180\n",
      "307/307 [==============================] - 119s 387ms/step - loss: 0.1679 - acc: 0.9532\n",
      "Epoch 82/180\n",
      "307/307 [==============================] - 119s 389ms/step - loss: 0.1939 - acc: 0.9467\n",
      "Epoch 83/180\n",
      "307/307 [==============================] - 122s 398ms/step - loss: 0.1823 - acc: 0.9505\n",
      "Epoch 84/180\n",
      "307/307 [==============================] - 123s 400ms/step - loss: 0.1779 - acc: 0.9520\n",
      "Epoch 85/180\n",
      "307/307 [==============================] - 121s 394ms/step - loss: 0.1675 - acc: 0.9547\n",
      "Epoch 86/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 0.1652 - acc: 0.9556\n",
      "Epoch 87/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 0.1865 - acc: 0.9500\n",
      "Epoch 88/180\n",
      "307/307 [==============================] - 123s 399ms/step - loss: 0.1646 - acc: 0.9525\n",
      "Epoch 89/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 0.1748 - acc: 0.9523\n",
      "Epoch 90/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 0.1446 - acc: 0.9583\n",
      "Epoch 91/180\n",
      "307/307 [==============================] - 119s 389ms/step - loss: 0.1565 - acc: 0.9559\n",
      "Epoch 92/180\n",
      "307/307 [==============================] - 122s 397ms/step - loss: 0.1790 - acc: 0.9525\n",
      "Epoch 93/180\n",
      "307/307 [==============================] - 122s 397ms/step - loss: 0.1698 - acc: 0.9541\n",
      "Epoch 94/180\n",
      "307/307 [==============================] - 120s 392ms/step - loss: 0.1688 - acc: 0.9569\n",
      "Epoch 95/180\n",
      "307/307 [==============================] - 120s 391ms/step - loss: 0.1528 - acc: 0.9600\n",
      "Epoch 96/180\n",
      "307/307 [==============================] - 121s 393ms/step - loss: 0.1511 - acc: 0.9615\n",
      "Epoch 97/180\n",
      "307/307 [==============================] - 122s 397ms/step - loss: 0.1417 - acc: 0.9608\n",
      "Epoch 98/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 0.1627 - acc: 0.9577\n",
      "Epoch 99/180\n",
      "307/307 [==============================] - 122s 398ms/step - loss: 0.1590 - acc: 0.9557\n",
      "Epoch 100/180\n",
      "307/307 [==============================] - 122s 397ms/step - loss: 0.1597 - acc: 0.9564\n",
      "Epoch 101/180\n",
      "307/307 [==============================] - 122s 397ms/step - loss: 0.1398 - acc: 0.9615\n",
      "Epoch 102/180\n",
      "307/307 [==============================] - 121s 395ms/step - loss: 0.1559 - acc: 0.9566\n",
      "Epoch 103/180\n",
      "307/307 [==============================] - 122s 396ms/step - loss: 0.1417 - acc: 0.9611\n",
      "Epoch 104/180\n",
      "307/307 [==============================] - 120s 392ms/step - loss: 0.1520 - acc: 0.9598\n",
      "Epoch 105/180\n",
      "307/307 [==============================] - 122s 399ms/step - loss: 0.1427 - acc: 0.9619\n",
      "Epoch 106/180\n",
      "307/307 [==============================] - 121s 394ms/step - loss: 0.1378 - acc: 0.9642\n",
      "Epoch 107/180\n",
      "307/307 [==============================] - 115s 375ms/step - loss: 0.1487 - acc: 0.9609\n",
      "Epoch 108/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1403 - acc: 0.9616\n",
      "Epoch 109/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1472 - acc: 0.9594\n",
      "Epoch 110/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1336 - acc: 0.9619\n",
      "Epoch 111/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1302 - acc: 0.9640\n",
      "Epoch 112/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1451 - acc: 0.9609\n",
      "Epoch 113/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1439 - acc: 0.9604\n",
      "Epoch 114/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1391 - acc: 0.9604\n",
      "Epoch 115/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1310 - acc: 0.9632\n",
      "Epoch 116/180\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1247 - acc: 0.9660\n",
      "Epoch 117/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1362 - acc: 0.9646\n",
      "Epoch 118/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1364 - acc: 0.9611\n",
      "Epoch 119/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1163 - acc: 0.9671\n",
      "Epoch 120/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1344 - acc: 0.9613\n",
      "Epoch 121/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1279 - acc: 0.9631\n",
      "Epoch 122/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1279 - acc: 0.9640\n",
      "Epoch 123/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1310 - acc: 0.9621\n",
      "Epoch 124/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1472 - acc: 0.9571\n",
      "Epoch 125/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1137 - acc: 0.9680\n",
      "Epoch 126/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1224 - acc: 0.9660\n",
      "Epoch 127/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1271 - acc: 0.9625\n",
      "Epoch 128/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1181 - acc: 0.9652\n",
      "Epoch 129/180\n",
      "307/307 [==============================] - 106s 345ms/step - loss: 0.1215 - acc: 0.9628\n",
      "Epoch 130/180\n",
      "307/307 [==============================] - 116s 379ms/step - loss: 0.1127 - acc: 0.9660\n",
      "Epoch 131/180\n",
      "307/307 [==============================] - 119s 389ms/step - loss: 0.1261 - acc: 0.9641\n",
      "Epoch 132/180\n",
      "307/307 [==============================] - 120s 390ms/step - loss: 0.1142 - acc: 0.9665\n",
      "Epoch 133/180\n",
      "307/307 [==============================] - 120s 391ms/step - loss: 0.1092 - acc: 0.9660\n",
      "Epoch 134/180\n",
      "307/307 [==============================] - 119s 388ms/step - loss: 0.1188 - acc: 0.9675\n",
      "Epoch 135/180\n",
      "307/307 [==============================] - 119s 389ms/step - loss: 0.1183 - acc: 0.9664\n",
      "Epoch 136/180\n",
      "307/307 [==============================] - 119s 386ms/step - loss: 0.1288 - acc: 0.9605\n",
      "Epoch 137/180\n",
      "307/307 [==============================] - 119s 389ms/step - loss: 0.1175 - acc: 0.9673\n",
      "Epoch 138/180\n",
      "307/307 [==============================] - 119s 389ms/step - loss: 0.1167 - acc: 0.9667\n",
      "Epoch 139/180\n",
      "307/307 [==============================] - 119s 387ms/step - loss: 0.1123 - acc: 0.9670\n",
      "Epoch 140/180\n",
      "307/307 [==============================] - 119s 386ms/step - loss: 0.1068 - acc: 0.9671\n",
      "Epoch 141/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1131 - acc: 0.9652\n",
      "Epoch 143/180\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1261 - acc: 0.9631\n",
      "Epoch 144/180\n",
      "307/307 [==============================] - 104s 339ms/step - loss: 0.1029 - acc: 0.9673\n",
      "Epoch 145/180\n",
      "307/307 [==============================] - 104s 339ms/step - loss: 0.1151 - acc: 0.9659\n",
      "Epoch 146/180\n",
      "307/307 [==============================] - 104s 338ms/step - loss: 0.1076 - acc: 0.9696\n",
      "Epoch 147/180\n",
      "307/307 [==============================] - 104s 339ms/step - loss: 0.1112 - acc: 0.9681\n",
      "Epoch 148/180\n",
      "307/307 [==============================] - 111s 360ms/step - loss: 0.1012 - acc: 0.9699\n",
      "Epoch 149/180\n",
      "307/307 [==============================] - 113s 369ms/step - loss: 0.1088 - acc: 0.9676\n",
      "Epoch 150/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1178 - acc: 0.9657\n",
      "Epoch 151/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1111 - acc: 0.9670\n",
      "Epoch 152/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1030 - acc: 0.9674\n",
      "Epoch 153/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1067 - acc: 0.9675\n",
      "Epoch 154/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.0921 - acc: 0.9732\n",
      "Epoch 155/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1061 - acc: 0.9672\n",
      "Epoch 156/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1127 - acc: 0.9665\n",
      "Epoch 157/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1061 - acc: 0.9669\n",
      "Epoch 158/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1007 - acc: 0.9689\n",
      "Epoch 159/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1016 - acc: 0.9684\n",
      "Epoch 160/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.0992 - acc: 0.9692\n",
      "Epoch 161/180\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1001 - acc: 0.9690\n",
      "Epoch 162/180\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1085 - acc: 0.9665\n",
      "Epoch 163/180\n"
=======
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
      "Epoch 1/200\n",
      "307/307 [==============================] - 120s 390ms/step - loss: 5.6699 - acc: 0.1038\n",
      "Epoch 2/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 4.7876 - acc: 0.1285\n",
      "Epoch 3/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 4.1200 - acc: 0.1677\n",
      "Epoch 4/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 3.5708 - acc: 0.2236\n",
      "Epoch 5/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 3.0354 - acc: 0.3207\n",
      "Epoch 6/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 2.6025 - acc: 0.3915\n",
      "Epoch 7/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 2.2354 - acc: 0.4653\n",
      "Epoch 8/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 1.9268 - acc: 0.5198\n",
      "Epoch 9/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 1.7021 - acc: 0.5707\n",
      "Epoch 10/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 1.4531 - acc: 0.6308\n",
      "Epoch 11/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 1.3018 - acc: 0.6556\n",
      "Epoch 12/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 1.1334 - acc: 0.6965\n",
      "Epoch 13/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 1.0285 - acc: 0.7198\n",
      "Epoch 14/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.9161 - acc: 0.7497\n",
      "Epoch 15/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.8248 - acc: 0.7764\n",
      "Epoch 16/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.7503 - acc: 0.7961\n",
      "Epoch 17/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.7121 - acc: 0.8045\n",
      "Epoch 18/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.6415 - acc: 0.8217\n",
      "Epoch 19/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.5848 - acc: 0.8348\n",
      "Epoch 20/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.5728 - acc: 0.8359\n",
      "Epoch 21/200\n",
      "307/307 [==============================] - 105s 344ms/step - loss: 0.5666 - acc: 0.8372\n",
      "Epoch 22/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.5093 - acc: 0.8573\n",
      "Epoch 23/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.4835 - acc: 0.8618\n",
      "Epoch 24/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.4632 - acc: 0.8714\n",
      "Epoch 25/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.4524 - acc: 0.8718\n",
      "Epoch 26/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.4268 - acc: 0.8817\n",
      "Epoch 27/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.3837 - acc: 0.8941\n",
      "Epoch 28/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.3958 - acc: 0.8906\n",
      "Epoch 29/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.3815 - acc: 0.8918\n",
      "Epoch 30/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.3740 - acc: 0.8980\n",
      "Epoch 31/200\n",
      "307/307 [==============================] - 105s 344ms/step - loss: 0.3881 - acc: 0.8932\n",
      "Epoch 32/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.3692 - acc: 0.8983\n",
      "Epoch 33/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.3309 - acc: 0.9100\n",
      "Epoch 34/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.3047 - acc: 0.9106\n",
      "Epoch 35/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2898 - acc: 0.9210\n",
      "Epoch 36/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.3054 - acc: 0.9195\n",
      "Epoch 37/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.3057 - acc: 0.9174\n",
      "Epoch 38/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2934 - acc: 0.9205\n",
      "Epoch 39/200\n",
      "307/307 [==============================] - 105s 344ms/step - loss: 0.2975 - acc: 0.9164\n",
      "Epoch 40/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2734 - acc: 0.9300\n",
      "Epoch 41/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.2739 - acc: 0.9231\n",
      "Epoch 42/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2755 - acc: 0.9245\n",
      "Epoch 43/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.3036 - acc: 0.9155\n",
      "Epoch 44/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2706 - acc: 0.9279\n",
      "Epoch 45/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2552 - acc: 0.9312\n",
      "Epoch 46/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2368 - acc: 0.9344\n",
      "Epoch 47/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2326 - acc: 0.9343\n",
      "Epoch 48/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2430 - acc: 0.9351\n",
      "Epoch 49/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.2278 - acc: 0.9399\n",
      "Epoch 50/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2270 - acc: 0.9401\n",
      "Epoch 51/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.2345 - acc: 0.9399\n",
      "Epoch 52/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.2120 - acc: 0.9463\n",
      "Epoch 53/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2119 - acc: 0.9458\n",
      "Epoch 54/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2332 - acc: 0.9386\n",
      "Epoch 55/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2369 - acc: 0.9340\n",
      "Epoch 56/200\n",
      "307/307 [==============================] - 107s 348ms/step - loss: 0.2205 - acc: 0.9408\n",
      "Epoch 57/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2222 - acc: 0.9408\n",
      "Epoch 58/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2094 - acc: 0.9449\n",
      "Epoch 59/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.2156 - acc: 0.9441\n",
      "Epoch 60/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.1951 - acc: 0.9491\n",
      "Epoch 61/200\n",
      "307/307 [==============================] - 105s 344ms/step - loss: 0.1863 - acc: 0.9495\n",
      "Epoch 62/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.2027 - acc: 0.9479\n",
      "Epoch 63/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1969 - acc: 0.9476\n",
      "Epoch 64/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1988 - acc: 0.9490\n",
      "Epoch 65/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1931 - acc: 0.9488\n",
      "Epoch 66/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1869 - acc: 0.9470\n",
      "Epoch 67/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1991 - acc: 0.9461\n",
      "Epoch 68/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1783 - acc: 0.9547\n",
      "Epoch 69/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1626 - acc: 0.9560\n",
      "Epoch 70/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1726 - acc: 0.9559\n",
      "Epoch 71/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1816 - acc: 0.9526\n",
      "Epoch 72/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1723 - acc: 0.9550\n",
      "Epoch 73/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1695 - acc: 0.9548\n",
      "Epoch 74/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1817 - acc: 0.9523\n",
      "Epoch 75/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1690 - acc: 0.9542\n",
      "Epoch 76/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1771 - acc: 0.9512\n",
      "Epoch 77/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1585 - acc: 0.9563\n",
      "Epoch 78/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1583 - acc: 0.9587\n",
      "Epoch 79/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1630 - acc: 0.9582\n",
      "Epoch 80/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1566 - acc: 0.9566\n",
      "Epoch 81/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1630 - acc: 0.9563\n",
      "Epoch 82/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1542 - acc: 0.9596\n",
      "Epoch 83/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1395 - acc: 0.9651\n",
      "Epoch 84/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1613 - acc: 0.9578\n",
      "Epoch 85/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1539 - acc: 0.9592\n",
      "Epoch 86/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1441 - acc: 0.9623\n",
      "Epoch 87/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1381 - acc: 0.9627\n",
      "Epoch 88/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1498 - acc: 0.9593\n",
      "Epoch 89/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1476 - acc: 0.9604\n",
      "Epoch 90/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1590 - acc: 0.9552\n",
      "Epoch 91/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1375 - acc: 0.9610\n",
      "Epoch 92/200\n",
      "307/307 [==============================] - 105s 340ms/step - loss: 0.1371 - acc: 0.9625\n",
      "Epoch 93/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1381 - acc: 0.9629\n",
      "Epoch 94/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1473 - acc: 0.9575\n",
      "Epoch 95/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1468 - acc: 0.9593\n",
      "Epoch 96/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1337 - acc: 0.9638\n",
      "Epoch 97/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1242 - acc: 0.9663\n",
      "Epoch 98/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1382 - acc: 0.9622\n",
      "Epoch 99/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1303 - acc: 0.9656\n",
      "Epoch 100/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1313 - acc: 0.9639\n",
      "Epoch 101/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1334 - acc: 0.9653\n",
      "Epoch 102/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1284 - acc: 0.9645\n",
      "Epoch 103/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1422 - acc: 0.9597\n",
      "Epoch 104/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1262 - acc: 0.9653\n",
      "Epoch 105/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1198 - acc: 0.9668\n",
      "Epoch 106/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1317 - acc: 0.9626\n",
      "Epoch 107/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1320 - acc: 0.9639\n",
      "Epoch 108/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1219 - acc: 0.9634\n",
      "Epoch 109/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1187 - acc: 0.9658\n",
      "Epoch 110/200\n",
      "307/307 [==============================] - 105s 340ms/step - loss: 0.1162 - acc: 0.9668\n",
      "Epoch 111/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1170 - acc: 0.9660\n",
      "Epoch 112/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1214 - acc: 0.9673\n",
      "Epoch 113/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1138 - acc: 0.9682\n",
      "Epoch 114/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1284 - acc: 0.9642\n",
      "Epoch 115/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1070 - acc: 0.9682\n",
      "Epoch 116/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1115 - acc: 0.9674\n",
      "Epoch 117/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1241 - acc: 0.9649\n",
      "Epoch 118/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1178 - acc: 0.9676\n",
      "Epoch 119/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1165 - acc: 0.9655\n",
      "Epoch 120/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1123 - acc: 0.9667\n",
      "Epoch 121/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1157 - acc: 0.9668\n",
      "Epoch 122/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.1141 - acc: 0.9665\n",
      "Epoch 123/200\n",
      "307/307 [==============================] - 105s 340ms/step - loss: 0.1249 - acc: 0.9642\n",
      "Epoch 124/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1076 - acc: 0.9688\n",
      "Epoch 125/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1040 - acc: 0.9698\n",
      "Epoch 126/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1167 - acc: 0.9667\n",
      "Epoch 127/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1075 - acc: 0.9686\n",
      "Epoch 128/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1162 - acc: 0.9646\n",
      "Epoch 129/200\n",
      "307/307 [==============================] - 106s 344ms/step - loss: 0.1060 - acc: 0.9677\n",
      "Epoch 130/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1150 - acc: 0.9664\n",
      "Epoch 131/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0984 - acc: 0.9699\n",
      "Epoch 132/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1035 - acc: 0.9694\n",
      "Epoch 133/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1037 - acc: 0.9672\n",
      "Epoch 134/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1047 - acc: 0.9686\n",
      "Epoch 135/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1111 - acc: 0.9662\n",
      "Epoch 136/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1021 - acc: 0.9697\n",
      "Epoch 137/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0996 - acc: 0.9696\n",
      "Epoch 138/200\n",
      "307/307 [==============================] - 105s 340ms/step - loss: 0.1077 - acc: 0.9669\n",
      "Epoch 139/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1016 - acc: 0.9684\n",
      "Epoch 140/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0999 - acc: 0.9697\n",
      "Epoch 141/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.1033 - acc: 0.9665\n",
      "Epoch 142/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.1066 - acc: 0.9667\n",
      "Epoch 143/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0992 - acc: 0.9697\n",
      "Epoch 144/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0990 - acc: 0.9690\n",
      "Epoch 145/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0920 - acc: 0.9703\n",
      "Epoch 146/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0910 - acc: 0.9714\n",
      "Epoch 147/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0973 - acc: 0.9694\n",
      "Epoch 148/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0936 - acc: 0.9712\n",
      "Epoch 149/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0953 - acc: 0.9694\n",
      "Epoch 150/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0958 - acc: 0.9701\n",
      "Epoch 151/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1004 - acc: 0.9672\n",
      "Epoch 152/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0989 - acc: 0.9661\n",
      "Epoch 153/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.1019 - acc: 0.9673\n",
      "Epoch 154/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0887 - acc: 0.9705\n",
      "Epoch 155/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.0964 - acc: 0.9701\n",
      "Epoch 156/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0908 - acc: 0.9708\n",
      "Epoch 157/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0914 - acc: 0.9701\n",
      "Epoch 158/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0966 - acc: 0.9696\n",
      "Epoch 159/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0879 - acc: 0.9694\n",
      "Epoch 160/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0918 - acc: 0.9704\n",
      "Epoch 161/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0897 - acc: 0.9699\n",
      "Epoch 162/200\n"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0840 - acc: 0.9724\n",
      "Epoch 163/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.0828 - acc: 0.9737\n",
      "Epoch 164/200\n",
      "307/307 [==============================] - 104s 340ms/step - loss: 0.0912 - acc: 0.9696\n",
      "Epoch 165/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.0948 - acc: 0.9690\n",
      "Epoch 166/200\n",
      "307/307 [==============================] - 114s 372ms/step - loss: 0.0934 - acc: 0.9684\n",
      "Epoch 167/200\n",
      "307/307 [==============================] - 355s 1s/step - loss: 0.0912 - acc: 0.9695\n",
      "Epoch 168/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0887 - acc: 0.9701\n",
      "Epoch 169/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0882 - acc: 0.9693\n",
      "Epoch 170/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0914 - acc: 0.9697\n",
      "Epoch 171/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0955 - acc: 0.9671\n",
      "Epoch 172/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.0835 - acc: 0.9732\n",
      "Epoch 173/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0908 - acc: 0.9699\n",
      "Epoch 174/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0805 - acc: 0.9731\n",
      "Epoch 175/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0910 - acc: 0.9705\n",
      "Epoch 176/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0867 - acc: 0.9703\n",
      "Epoch 177/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0900 - acc: 0.9704\n",
      "Epoch 178/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.0890 - acc: 0.9708\n",
      "Epoch 179/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0777 - acc: 0.9738\n",
      "Epoch 180/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0845 - acc: 0.9714\n",
      "Epoch 181/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0869 - acc: 0.9704\n",
      "Epoch 182/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.0832 - acc: 0.9714\n",
      "Epoch 183/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0840 - acc: 0.9706\n",
      "Epoch 184/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0809 - acc: 0.9714\n",
      "Epoch 185/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0903 - acc: 0.9674\n",
      "Epoch 186/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0791 - acc: 0.9710\n",
      "Epoch 187/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0797 - acc: 0.9720\n",
      "Epoch 188/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0825 - acc: 0.9705\n",
      "Epoch 189/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0860 - acc: 0.9699\n",
      "Epoch 190/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0774 - acc: 0.9728\n",
      "Epoch 191/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.0858 - acc: 0.9691\n",
      "Epoch 192/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0767 - acc: 0.9717\n",
      "Epoch 193/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0818 - acc: 0.9704\n",
      "Epoch 194/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0811 - acc: 0.9706\n",
      "Epoch 195/200\n",
      "307/307 [==============================] - 105s 341ms/step - loss: 0.0843 - acc: 0.9706\n",
      "Epoch 196/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0797 - acc: 0.9711\n",
      "Epoch 197/200\n",
      "307/307 [==============================] - 105s 343ms/step - loss: 0.0788 - acc: 0.9706\n",
      "Epoch 198/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0729 - acc: 0.9745\n",
      "Epoch 199/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0779 - acc: 0.9726\n",
      "Epoch 200/200\n",
      "307/307 [==============================] - 105s 342ms/step - loss: 0.0800 - acc: 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5bc0ffd68>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_dir = 'C:/Users/jdu12/Desktop/humpback/saved_model/DenseNet/'\n",
    "routine_dir = model_dir + \"routine-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "routine_save = ModelCheckpoint(routine_dir, monitor='acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=10)\n",
    "best_dir = model_dir + \"best-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "best_save = ModelCheckpoint(best_dir, monitor='acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "model.fit_generator(image_gen.flow(train, labels, batch_size=batch_size),\n",
    "          steps_per_epoch=train.shape[0]//batch_size,\n",
    "          epochs=epochs, verbose=1, callbacks=[routine_save, best_save])\n",
=======
    "model.fit_generator(image_gen.flow(x_train, y_train, batch_size=batch_size),\n",
    "          steps_per_epoch=  x_train.shape[0]//batch_size,\n",
    "          epochs=epochs, verbose=1, callback=[routine_save, best_save])\n",
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
    "          #class_weight=class_weight_dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 8,
=======
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(model_dir + 'first_DenseNet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading trained model\n",
    "model = load_model('C:/Users/jdu12/Desktop/humpback/saved_model/DenseNet/' + 'first_DenseNet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15610\n",
      "(15610, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# loading test images\n",
    "testPaths = list(paths.list_images('C:/Users/jdu12/Desktop/humpback/test/'))\n",
    "print(len(testPaths))\n",
    "test_images = np.array([get_image(img_path) for img_path in testPaths])/255\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading trained model\n",
    "model = load_model('C:/Users/jdu12/Desktop/humpback/saved_model/DenseNet/' + 'routine-150-0.97.hdf5')"
=======
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-527da95a1ebb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.applications.densenet import decode_predictions\n",
    "\n",
    "preds = model.predict(test_images[9000:9100])\n",
    "print(test_images[9000:9100].shape)\n",
    "print(preds.shape)\n",
    "print(preds[0:20,7])"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict!\n",
    "pred = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 86,
   "metadata": {},
=======
   "execution_count": 86,
   "metadata": {},
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
=======
   "execution_count": 86,
   "metadata": {},
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (850, 4251)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-c7537ebb21bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top)\u001b[0m\n\u001b[0;32m    200\u001b[0m                          \u001b[1;34m'a batch of predictions '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                          \u001b[1;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m                          'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         fpath = get_file('imagenet_class_index.json',\n",
      "\u001b[1;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (850, 4251)"
     ]
    }
   ],
   "source": [
    "print(decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-fcc34f3c1969>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#x = image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.reshape(1,SIZE,SIZE,1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mpredicted_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mpredicted_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_labels\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpredicted_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1835\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   "source": [
    "# testing and generating submission file\n",
    "import warnings\n",
    "from os.path import split\n",
    "\n",
    "with open(\"sample_submission.csv\",\"w\") as f:\n",
<<<<<<< HEAD
    "    f.write(\"Image,Id\\n\")\n",
    "    top_5 = np.argsort(pred)[:,-1:-6:-1]   # get the top 5 most likely classes\n",
    "    for i in range(top_5.shape[0]):\n",
    "        cur_tags = ''\n",
    "        cur_image_name = testPaths[i].split('/')[-1]\n",
    "        for j in range(5):\n",
    "            cur_tags = cur_tags + ' ' + class2id[top_5[i][j]]\n",
    "        f.write(\"%s,%s\\n\" %(cur_image_name, cur_tags))     "
=======
    "    with warnings.catch_warnings():\n",
    "        f.write(\"Image,Id\\n\")\n",
    "        warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "        #for image in test_images:\n",
    "            #img = ImportImage( image)\n",
    "            #x = img.astype( \"float32\")\n",
    "            #applying preprocessing to test images\n",
    "            #x = image_gen.standardize( x.reshape(1,SIZE,SIZE))\n",
    "            \n",
    "        #x = image\n",
    "        y = model.predict(test_images)#.reshape(1,SIZE,SIZE,1))\n",
    "        predicted_args = np.argsort(y)[0][::-1][:5]\n",
    "        predicted_tags = lohe.inverse_labels( predicted_args)\n",
    "        image = split(image)[-1]\n",
    "        predicted_tags = \" \".join( predicted_tags)\n",
    "        f.write(\"%s,%s\\n\" %(image, predicted_tags))"
>>>>>>> parent of 16fbf81... added submission file generation, whole pipeline done
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 7 6 5 4]\n",
      " [8 7 6 5 4]]\n"
     ]
    }
   ],
   "source": [
    "top_5 = np.argsort(pred)[:,-1:-6:-1]\n",
    "print(top_5.shape)\n",
    "a = np.asarray([[1, 2, 3, 4, 5, 6, 7, 8],[1, 2, 3, 4, 5, 6, 7, 8]])\n",
    "print(a[:,-1:-6:-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
