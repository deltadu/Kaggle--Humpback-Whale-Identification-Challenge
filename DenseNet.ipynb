{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import random\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.densenet import preprocess_input\n",
    "from keras.preprocessing.image import (random_rotation, random_shift, random_shear, random_zoom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single image to np array\n",
    "def get_image(img_path):\n",
    "    img = load_img(img_path, target_size=(224, 224))#.convert('L')\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "def to_one_hot(labels, preClass2id = None, preId2class = None):\n",
    "    if preId2class is None:\n",
    "        id2class = dict()\n",
    "        class2id = dict()      ##!!! class(integer) to id(whale class)\n",
    "        num_labels = []\n",
    "        counter = 0\n",
    "    else:\n",
    "        id2class = preId2class\n",
    "        class2id = preClass2id\n",
    "        num_labels = []\n",
    "        counter = len(class2id.keys())\n",
    "    for id in labels:\n",
    "        if id not in id2class.keys():\n",
    "            num_labels.append(counter)\n",
    "            id2class[id] = counter\n",
    "            class2id[counter] = id\n",
    "            counter += 1\n",
    "        else:\n",
    "            num_labels.append(id2class[id])\n",
    "    one_hot_labels = to_categorical(num_labels, num_classes = 4251)\n",
    "    return one_hot_labels, class2id, id2class, num_labels\n",
    "\n",
    "\n",
    "train_label_dir = '/home/jiaruizou/Desktop/CS543Final/train.csv'\n",
    "df = pd.read_csv(train_label_dir)\n",
    "\n",
    "labels = df['Id']\n",
    "labels, class2id, id2class, num_labels = to_one_hot(labels)\n",
    "\n",
    "# generate class weights\n",
    "from sklearn.utils import class_weight\n",
    "cw = class_weight.compute_class_weight('balanced', np.arange(len(class2id)), np.asarray(num_labels))\n",
    "cw = dict(enumerate(cw.flatten(), 1))\n",
    "# since cw start at 1 instead of 0, we need to offset this by 1\n",
    "cw_z = dict()\n",
    "for key in cw:\n",
    "    cw_z[key-1] = cw[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9081\n",
      "(9081, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# loading train images\n",
    "trainPaths = list(paths.list_images('/home/jiaruizou/Desktop/CS543Final/train/'))\n",
    "print(len(trainPaths))\n",
    "train = np.array([get_image(img_path) for img_path in trainPaths])\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and val\n",
    "# The dataset is super unbalanced, as there are many classes that contains only 1 image\n",
    "# As a result, train/val data cannot be split before generating more data by augmentation\n",
    "train_dir = '/home/jiaruizou/Desktop/CS543Final/train/'\n",
    "\n",
    "num_categories = len(df['Id'].unique())\n",
    "#print(num_categories)\n",
    "validation = np.zeros((num_categories, 224, 224, 3))\n",
    "validation_y = []\n",
    "\n",
    "i = 0\n",
    "for id in df['Id'].unique():\n",
    "    validation_y.append(id)\n",
    "    im = df[df['Id'] == id].sample(1)\n",
    "    name =  np.array(im.get('Image'))[0]\n",
    "    im = get_image(train_dir + name)\n",
    "\n",
    "    # https://www.kaggle.com/lextoumbourou/humpback-whale-id-data-and-aug-exploration\n",
    "    x = -1#random.randint(0, 3)\n",
    "    if x == -1:\n",
    "        validation[i,:,:,:] = im # for debugging\n",
    "    if x == 0:\n",
    "        validation[i,:, :, :] = random_rotation(im, 30, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    if x == 1:\n",
    "        validation[i,:, :, :] = random_shift(im, wrg=0.1, hrg=0.3, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    if x == 2:\n",
    "        validation[i,:, :, :] = random_shear(im, intensity=0.4, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    if x == 3:\n",
    "        validation[i,:, :, :] = random_zoom(im, zoom_range=(1.5, 0.7), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    i = i + 1\n",
    "\n",
    "validation_y = to_one_hot(validation_y, class2id, id2class)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data generator\n",
    "#use of an image generator for preprocessing and data augmentation\n",
    "image_gen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = ImageDataGenerator()\n",
    "train_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9081, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the model\n",
    "model = keras.applications.densenet.DenseNet121(include_top=True, weights=None, classes=4251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "283/283 [==============================] - 136s 480ms/step - loss: 8.4782 - acc: 1.1042e-04 - val_loss: 8.6319 - val_acc: 4.7348e-04\n",
      "Epoch 2/200\n",
      "283/283 [==============================] - 94s 331ms/step - loss: 8.2969 - acc: 0.0000e+00 - val_loss: 9.3698 - val_acc: 2.3674e-04\n",
      "Epoch 3/200\n",
      "283/283 [==============================] - 95s 334ms/step - loss: 7.9898 - acc: 6.6255e-04 - val_loss: 9.2083 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "283/283 [==============================] - 94s 333ms/step - loss: 7.5328 - acc: 7.7297e-04 - val_loss: 9.6418 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "283/283 [==============================] - 94s 331ms/step - loss: 7.0542 - acc: 0.0021 - val_loss: 10.1663 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "283/283 [==============================] - 94s 333ms/step - loss: 6.5584 - acc: 0.0044 - val_loss: 10.8190 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "283/283 [==============================] - 95s 334ms/step - loss: 6.0551 - acc: 0.0119 - val_loss: 11.5490 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "283/283 [==============================] - 94s 332ms/step - loss: 5.4428 - acc: 0.0325 - val_loss: 12.0595 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "283/283 [==============================] - 95s 335ms/step - loss: 4.8449 - acc: 0.0719 - val_loss: 12.4250 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "283/283 [==============================] - 94s 333ms/step - loss: 4.1964 - acc: 0.1266 - val_loss: 14.0794 - val_acc: 4.7348e-04\n",
      "Epoch 11/200\n",
      "283/283 [==============================] - 94s 334ms/step - loss: 3.5125 - acc: 0.1945 - val_loss: 13.9137 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "283/283 [==============================] - 94s 333ms/step - loss: 2.8880 - acc: 0.2636 - val_loss: 14.4946 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      "283/283 [==============================] - 94s 333ms/step - loss: 2.3166 - acc: 0.3339 - val_loss: 14.6658 - val_acc: 2.3674e-04\n",
      "Epoch 14/200\n",
      "283/283 [==============================] - 95s 335ms/step - loss: 1.8676 - acc: 0.4005 - val_loss: 14.5507 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "283/283 [==============================] - 95s 335ms/step - loss: 1.4839 - acc: 0.4679 - val_loss: 14.8837 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "208/283 [=====================>........] - ETA: 20s - loss: 1.1462 - acc: 0.5310"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_dir = '/home/jiaruizou/Desktop/CS543Final/saved_model/DenseNet/'\n",
    "routine_dir = model_dir + \"routine-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "routine_save = ModelCheckpoint(routine_dir, monitor='acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=10)\n",
    "best_dir = model_dir + \"best-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "best_save = ModelCheckpoint(best_dir, monitor='acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=4)\n",
    "\n",
    "\n",
    "hist = model.fit_generator(train_gen.flow(train, labels, batch_size=batch_size),\n",
    "                    steps_per_epoch=train.shape[0]//batch_size,\n",
    "                    epochs=epochs, verbose=1, callbacks=[routine_save, best_save], class_weight=cw_z,\n",
    "                    #       validation_data=(validation, validation_y))\n",
    "                    validation_data=val_gen.flow(validation, validation_y, batch_size=batch_size),\n",
    "                           validation_steps=validation.shape[0]//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test images\n",
    "testPaths = list(paths.list_images('/home/jiaruizou/Desktop/CS543Final/test/'))\n",
    "print(len(testPaths))\n",
    "test_images = np.array([get_image(img_path) for img_path in testPaths])\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading trained model\n",
    "model_name = 'routine-170-0.99'\n",
    "model = load_model('/home/jiaruizou/Desktop/CS543Final/saved_model/DenseNet/' + model_name+ '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict!\n",
    "pred = model.predict(test_images)\n",
    "\n",
    "# testing and generating submission file\n",
    "import warnings\n",
    "from os.path import split\n",
    "\n",
    "pred_dir = \"/home/jiaruizou/Desktop/CS543Final/prediction/DenseNet/\"\n",
    "\n",
    "with open(pred_dir + model_name + \".csv\", \"w\") as f:\n",
    "    f.write(\"Image,Id\\n\")\n",
    "    top_5 = np.argsort(pred)[:,-1:-6:-1]   # get the top 5 most likely classes\n",
    "    for i in range(top_5.shape[0]):\n",
    "        cur_tags = ''\n",
    "        cur_image_name = testPaths[i].split('/')[-1]\n",
    "        for j in range(5):\n",
    "            cur_tags = cur_tags + ' ' + class2id[top_5[i][j]]\n",
    "        f.write(\"%s,%s\\n\" %(cur_image_name, cur_tags))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import plotHistory\n",
    "plotHistory.plotTrainingHistory(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
